<div align="center">

| Previous Page | Next Phase |
|:-------------------------------------------:|:---------------------------------------------:|
| [Footprinting](2.0-Footprinting.md) | [Fingerprinting](../3-Fingerprinting/3.0-Fingerprinting.md) |

</div>

<br>
<br>

## Tools Reference Table

<br>

<p align=center>

| Tool | Purpose | Link |
|:-----|:--------|:---------------|
| [**Google Dorks**](#google-hacking-dorks) | Find publicly available information | [google.com](https://google.com) |
| [**theHarvester**](#theharvester) | Emails & subdomains | [GitHub](https://github.com/laramies/theHarvester) |
| [**Sherlock**](#sherlock) | Username search across social media | [GitHub](https://github.com/sherlock-project/sherlock) |
| [**Maltego**](#maltego) | Visual relationship mapping | [maltego.com](https://www.maltego.com/) |
| [**Traceroute**](#traceroute-network-path-mapping) | Network path mapping | Built-in |
| [**WHOIS**](#whois-ownership) | Domain ownership lookup | Built-in |
| [**Dig**](#dig-dns-mapping) | DNS record queries | Built-in |
| [**Dnsenum**](#dnsenum-dns-mapping) | DNS enumeration | [GitHub](https://github.com/fwaeytens/dnsenum) |
| [**Shodan**](#shodan) | Search IoT devices & servers | [shodan.io](https://www.shodan.io/) |
| [**FOCA**](#foca) | Document metadata extraction | [GitHub](https://github.com/ElevenPaths/FOCA) |
| [**BuiltWith**](#builtwith) | Website technology lookup | [builtwith.com](https://builtwith.com/) |
| [**Wayback Machine**](#wayback-machine) | Historical website snapshots | [archive.org](https://web.archive.org/) |
| [**Netcraft**](#netcraft) | Site report & hosting history | [netcraft.com](https://sitereport.netcraft.com/) |

</p>

<br>

> **External References:**
> * [**BloodHound**](https://github.com/BloodHoundAD/BloodHound) - The industry standard for mapping Active Directory trust relationships and attack paths.
> * [**ADSecurity.org**](https://adsecurity.org/) - Comprehensive resource on Active Directory security and reconnaissance.
> * [**Cas van Cooten (Windows Recon)**](https://casvancooten.com/) - A great blog and resource for Windows internal reconnaissance cheatsheets.
> * [**Hunter.io**](https://hunter.io/) - Email finder.

<br>
<br>

# 1-OSINT & Public Data Gathering

Open Source Intelligence (OSINT) involves **collecting publicly available information about a target** from search engines, social media, public records, and other accessible sources. This data helps build a comprehensive profile of the target without any direct interaction.

<br>

## Google Hacking (Dorks)
> *Reference: [Google Hacking Database](https://www.exploit-db.com/google-hacking-database)*

Google Dorking uses advanced search operators to filter results and find sensitive information or vulnerable systems.

#### Search Operators

<p align=center>

| Operator | Description | Example |
|:---------|:------------|:--------|
| `intitle:` | Pages with term in title | `intitle:"admin login"` |
| `allintitle:` | Pages with ALL terms in title (exact order) | `allintitle:admin panel login` |
| `intext:` | Pages with term in body | `intext:"password"` |
| `allintext:` | Pages with ALL terms in body | `allintext:username password` |
| `inurl:` | Pages with term in URL | `inurl:admin` |
| `allinurl:` | Pages with ALL terms in URL | `allinurl:admin login` |
| `site:` | Limit to specific domain | `site:*.ugr.es` |
| `filetype:` | Specific file type | `filetype:pdf` |
| `link:` | Pages linking to URL | `link:example.com` |
| `related:` | Similar websites | `related:example.com` |
| `cache:` | Google's cached version | `cache:example.com` |
| `info:` | Info about a website | `info:example.com` |
| `before:` | Indexed before date | `before:2022-01-01` |
| `after:` | Indexed after date | `after:2022-01-01` |

</p>

#### Logic Operators

<p align=center>

| Operator | Description | Example |
|:---------|:------------|:--------|
| `AND` | Both terms required | `admin AND password` |
| `OR` | Either term | `admin OR administrator` |
| `-` (NOT) | Exclude term | `admin -login` |
| `*` | Wildcard | `site:cm-*.pt` |
| `" "` | Exact phrase | `"index of"` |
| `( )` | Group operators | `(admin OR root) site:target.com` |

</p>

#### Practical Examples

```bash
# == Find PDFs on Portuguese government sites == #
site:*.gov.pt filetype:pdf

# == Find exposed directories == #
intitle:"index of" "parent directory"

# == Find login pages excluding main site == #
inurl:login -site:target.com

# == Find emails disclosed by an organization == #
site:target.com "@*.com"

# == Pages with "password" in text but NOT in title == #
intext:password -intitle:password

# == Find config files == #
filetype:conf OR filetype:cfg site:target.com
```
> **Tip:** Use `-` operator to filter out noise (false positives) from results.  


#### Limitations

<p align=center>

| Limitation | Impact |
|:-----------|:-------|
| **32-word limit** | Keep queries concise |
| **Max 200 results** | Use filters to narrow scope |
| **Non-indexed content** | Deep web/dynamic pages invisible |
| **SafeSearch filtering** | May hide sensitive results |
| **Copyright removal** | Pirated content delisted |
| **Date imprecision** | Dates = Google indexing, not creation |
| **Non-commutative** | Word order affects results |

</p>


<br>

## TheHarvester
> *HomePage: https://github.com/laramies/theHarvester*

<p align="center">
    <img width="200" src="../images/theHarvester_logo.png" alt="theHarvester Logo">
</p>

theHarvester is a simple to use, yet powerful command-line tool designed to be used during the reconnaissance stage of a red team assessment or penetration test. It performs open source intelligence (OSINT) gathering to help determine a domain's external threat landscape. **The tool gathers names, emails, IPs, subdomains, and URLs by using multiple public resources**.

```bash
# ========================================= #
# Kali Linux / Ubuntu / Debian INSTALLATION #
# ========================================= #

sudo apt update
sudo apt install theharvester

# ========================================= #
#           DOCKER INSTALLATION             #
# ========================================= #

git clone https://github.com/laramies/theHarvester.git
cd theHarvester
docker build -t my-harvester .

# == Running it == #
docker run my-harvester -d target.com -b google


# ========================================= #
#                   SINTAX                  #
# ========================================= #

theharvester [-h] -d DOMAIN [-l LIMIT] [-S START] [-p] [-s] [--screenshot SCREENSHOT] [-v] [-e DNS_SERVER] [-t][-r[DNS_RESOLVE]] [-n] [-c] [-f FILENAME] [-b SOURCE]

```

<br>

### TheHarvester Cheat Sheet

| Option | Description | Example |
|:-------|:------------|:--------|
| `-d` | Target domain to search | `-d target.com` |
| `-l` | Limit results (depth of search - more depht slower results - 100,500,1000) | `-l 500` |
| `-b` | Data source(s) to query (options as of may 2018: google, googleCSE, bing, bingapi, pgp, linkedin, google-profiles, jigsaw, twitter, googleplus, all)| `-b google,bing,linkedin` |
| `-f` | Output filename (HTML/XML) | `-f results.html` |
| `-s` | Use Shodan for host discovery | `-s` |
| `-p` | Use proxies for requests | `-p` |
| `-v` | Verify hostnames via DNS | `-v` |
| `-e` | Specify DNS server | `-e 8.8.8.8` |
| `-t` | Perform DNS TLD expansion | `-t` |
| `-r` | Perform reverse DNS lookup | `-r` |
| `-n` | Perform DNS brute force | `-n` |
| `-c` | Perform DNS brute force with TLD | `-c` |
| `-S` | Start result number | `-S 0` |
| `--screenshot` | Take screenshots of discovered hosts | `--screenshot /path/` |


#### Practical Examples

```bash
# Basic search on Google
theHarvester -d target.com -b google

# Deep search with multiple sources
theHarvester -d target.com -l 500 -b google,bing,linkedin,dnsdumpster

# Save results to file
theHarvester -d target.com -b all -f target_results

# Search with DNS resolution
theHarvester -d target.com -b google -v -e 8.8.8.8

# Full reconnaissance
theHarvester -d target.com -l 1000 -b all -s -v -f full_report
```

<br>

## Sherlock
> *HomePage: https://github.com/sherlock-project/sherlock*

<p align="center">
    <img width=200 src="../images/sherlock_logo.png" alt="Sherlock Logo">
</p>

Sherlock is a powerful command-line tool used to hunt down social media accounts by username across 400+ social networks. It is a staple in the OSINT phase for finding targets' footprints on platforms like Instagram, Twitter, Reddit, Telegram, and obscure forums.

```bash
# ========================================= #
#             LINUX INSTALLATION            #
# ========================================= #

git clone https://github.com/sherlock-project/sherlock.git
cd sherlock

python3 -m venv venv
source venv/bin/activate

pip install .
#python3 -m pip install .


# ========================================= #
#             DOCKER INSTALLATION           #
# ========================================= #

docker pull sherlock/sherlock
docker run --rm sherlock/sherlock "<user>"


# ========================================= #
#                   SINTAX                  #
# ========================================= #

sherlock [-h] [--version] [--verbose] [--folderoutput FOLDEROUTPUT] [--output OUTPUT] [--csv] [--xlsx] [--site SITE_NAME] [--proxy PROXY_URL] [--dump-response] [--json JSON_FILE] [--timeout TIMEOUT] [--print-all]
                [--print-found] [--no-color] [--browse] [--local] [--nsfw] [--no-txt] [--txt] [--ignore-exclusions]
                USERNAMES [USERNAMES ...]


sherlock --help
```

#### Sherlock Cheat Sheet

<p align="center">

| Option | Description | Example |
|:-------|:------------|:--------|
| `USERNAMES` | Target username(s) to check. Use `{?}` to check variations (`_`, `-`, `.`). | `sherlock user1` or `sherlock user{?}123` |
| `--version` | Display version information and dependencies. | `sherlock --version` |
| `--verbose` / `-v` / `-d` | Display extra debugging info and metrics. | `sherlock user1 -v` |
| `--folderoutput` / `-fo` | Save results to a specific folder (best for multiple users). | `sherlock user1 -fo /tmp/results` |
| `--output` / `-o` | Save result to a specific file (single username only). | `sherlock user1 -o evidence.txt` |
| `--csv` | Create a CSV report file. | `sherlock user1 --csv` |
| `--xlsx` | Create an Excel (.xlsx) report file. | `sherlock user1 --xlsx` |
| `--site` | Limit search to specific sites only. | `sherlock user1 --site instagram` |
| `--proxy` / `-p` | Route traffic through a proxy (HTTP/SOCKS). | `sherlock user1 -p socks5://127.0.0.1:9050` |
| `--dump-response` | Dump raw HTTP response to file for debugging. | `sherlock user1 --dump-response` |
| `--json` / `-j` | Load custom site data from a JSON file or URL. | `sherlock user1 --json custom_sites.json` |
| `--timeout` | Time (in seconds) to wait for response (Default: 60). | `sherlock user1 --timeout 10` |
| `--print-all` | Output sites where the username was NOT found too. | `sherlock user1 --print-all` |
| `--print-found` | Output only sites where the username was found. | `sherlock user1 --print-found` |
| `--no-color` | Disable colored terminal output. | `sherlock user1 --no-color` |
| `--browse` / `-b` | Open all found results in the default browser. | `sherlock user1 -b` |
| `--local` / `-l` | Force use of local `data.json` (offline definitions). | `sherlock user1 -l` |
| `--nsfw` | Include NSFW sites in the scan. | `sherlock user1 --nsfw` |
| `--no-txt` | Disable saving results to a .txt file. | `sherlock user1 --no-txt` |
| `--txt` | Save results as a .txt file (default behavior). | `sherlock user1 --txt` |
| `--ignore-exclusions` | Ignore site exclusion list and check all sites. | `sherlock user1 --ignore-exclusions` |

</p>

#### Practical Examples

```bash
# Basic search
sherlock user123

# Search multiple users and save to a folder
sherlock user1 user2 --folderoutput ./evidence

# Clean search (Found only) + CSV Export
sherlock user123 --print-found --csv

# Search specific sites via Tor Proxy
sudo service tor start
sherlock user123 --site instagram  -p socks5://127.0.0.1:9050

# Smart search for variations (checks user.123, user-123, user_123)
sherlock user{?}123

```

<br>

## Maltego
> *HomePage: https://www.maltego.com/*

<p align="center">
    <img width="300" src="../images/maltego_logo.png" alt="Maltego">
</p>

Visual link analysis tool for mapping relationships between people, companies, domains, and infrastructure.


<br>
<br>



# 2-Infrastructure Reconnaissance

"The Network." Mapping the IP space, DNS records, and mail servers.

<br>

## Traceroute (Network Path Mapping)
Traceroute is a fundamental **network diagnostic tool** used to display the route (path) and measure transit delays of packets across an Internet Protocol (IP) network. In a Red Team context, it is critical for Infrastructure Reconnaissance to identify network topology, firewall locations, and potential bottlenecks before launching active attacks.

```bash
# Built-in tool
# Note: Windows uses tracert instead of traceroute


# ========================================= #
#                   SINTAX                  #
# ========================================= #

traceroute [-46dFITUnreAV] [-f first_ttl] [-g gate,...]
               [-i device] [-m max_ttl] [-p port] [-s src_addr]
               [-q nqueries] [-N squeries] [-t tos]
               [-l flow_label] [-w waittimes] [-z sendwait] [-UL] [-D]
               [-P proto] [--sport=port] [-M method] [-O mod_options]
               [--mtu] [--back]
               host [packet_len]
```
#### Traceroute Cheat Sheet

<p align="center">

| Option (Linux) | Option (Windows) | Description | Example (Linux) |
|:-------|:-------|:------------|:--------|
| `<host>` | `target_name` | The target IP or Domain Name. | `traceroute google.com` |
| `-n` | `-d` | **Do not resolve IP addresses to hostnames.** (Faster). | `traceroute -n 8.8.8.8` |
| `-I` | N/A | Use **ICMP** ECHO instead of UDP (Default). Mimics Windows behavior. | `traceroute -I google.com` |
| `-T` | N/A | Use **TCP** SYN for probes (Bypasses many firewalls). | `sudo traceroute -T google.com` |
| `-p <port>` | N/A | Set the destination port (useful with `-T`). | `traceroute -T -p 443 google.com` |
| `-m <max_ttl>` | `-h <max_hops>` | Set the max number of hops (TTL) to probe (Default: 30). | `traceroute -m 50 google.com` |
| `-w <waittime>` | `-w <timeout>` | Set the time (in seconds) to wait for a response. | `traceroute -w 2 google.com` |
| `-4` | `-4` | Force IPv4. | `traceroute -4 google.com` |
| `-6` | `-6` | Force IPv6. | `traceroute -6 google.com` |
| `-i <interface>` | `-S <srcaddr>` | Specify a network interface/source IP to send packets from. | `traceroute -i eth0 google.com` |

</p>

```bash
# 1. Standard Trace (UDP on Linux, ICMP on Windows)
# Good for general connectivity checks.
traceroute target.com

# 2. Fast Trace (No DNS Resolution)
# Best for quick mapping when you only care about IPs.
traceroute -n target.com

# Firewall Bypass (TCP Trace - Red Team Essential)
# Use this when standard traceroute is blocked (shows * * *).
# Sends TCP SYN packets to port 80 (HTTP) or 443 (HTTPS).
sudo traceroute -T -p 443 target.com

# 4. TCP trace to specific service ports (Identify filtered ports)
sudo traceroute -T -p 22 target.com    # SSH
sudo traceroute -T -p 3389 target.com  # RDP

# Specific source interface - useful when connected via VPN or multiple network interfaces.
sudo traceroute -i tun0 target.com

# ebugging Latency (Slow/lossy networks)
traceroute -w 3 target.com

# ICMP Trace (Windows-style behavior on Linux)
traceroute -I target.com
```

<br>


## WHOIS (Ownership)

Whois is a query and response protocol that is widely used for querying databases that store the registered users or assignees of an Internet resource, such as a domain name, an IP address block, or an autonomous system. In a Red Team context, it is the first step of Infrastructure Reconnaissance to identify the organization's legal address, technical contacts (social engineering targets), and IP ranges (CIDR).

```bash

# ========================================= #
#             LINUX INSTALLATION            #
# ========================================= #

sudo apt update
sudo apt install whois


# ========================================= #
#                   SINTAX                  #
# ========================================= #

whois [OPTION]... OBJECT...
```

#### Whois Cheat Sheet

<p align="center">

| Option | Description | Example |
|:-------|:------------|:--------|
| `-h <HOST>` | Connect to a specific database server. | `whois -h whois.ripe.net 1.1.1.1` |
| `-p <PORT>` | Connect to a specific port. | `whois -p 43 target.com` |
| `-I` | Query `whois.iana.org` and follow referral (Root lookup). | `whois -I 8.8.8.8` |
| `-H` | Hide legal disclaimers (Cleaner output). | `whois -H target.com` |
| `--verbose` | Explain what is being done. | `whois --verbose target.com` |
| `--no-recursion` | Disable recursion from registry to registrar. | `whois --no-recursion target.com` |
| **RIPE / Advanced** | **(Flags for RIPE-like servers e.g., Europe)** | |
| `-x` | Exact match only. | `whois -x 212.0.0.1` |
| `-b` | Return brief IP ranges with abuse contact (Anti-Spam focused). | `whois -b 212.0.0.1` |
| `-B` | Turn off object filtering (Show emails). | `whois -B target.com` |
| `-m` | Find one level *more specific* matches (Sub-nets). | `whois -m 212.0.0.0/16` |
| `-M` | Find *all levels* of more specific matches. | `whois -M 212.0.0.0/16` |
| `-l` | Find one level *less specific* match (Super-net/Parent). | `whois -l 212.0.0.1` |
| `-i <ATTR>` | Inverse lookup (Search by Admin Name/Email instead of IP). | `whois -i admin-c "Admin Name"` |
| `-T <TYPE>` | Only look for specific objects (e.g., `person`, `org`). | `whois -T person "Smith"` |
| `-a` | Search all mirrored databases. | `whois -a target.com` |

</p>

```bash
# == Basic Domain Lookup ==
whois target.com

# 2. IP Address Lookup (NetBlock Identification)
# Critical for Red Team: Tells you the CIDR (IP Range) the company owns.
whois 203.0.113.10

# 3. Query a Specific Server
# Sometimes the default server doesn't have the info. Ask the specific registrar.
whois -h whois.godaddy.com target.com

# 4. Clean Output (Linux)
# Hides the huge legal text blocks.
whois -H target.com | grep -i "Tech Email"
```


<br>

## Dig (DNS mapping)

Dig is a flexible tool for interrogating DNS name servers. It performs DNS lookups and displays the answers that are returned from the name server(s) that were queried.

```bash

# ========================================= #
#             LINUX INSTALLATION            #
# ========================================= #

# == Kali/Ubuntu (Part of 'dnsutils') == #
sudo apt update
sudo apt install dnsutils

# == RedHat/CentOS == #
sudo yum install bind-utils


# ========================================= #
#                   SINTAX                  #
# ========================================= #

dig [@global-server] [domain] [q-type] [q-class] {q-opt}
            {global-d-opt} host [@local-server] {local-d-opt}
            [ host [@local-server] {local-d-opt} [...]]
```

#### Dig Cheat Sheet

<p align="center">

| Option | Description | Example |
|:-------|:------------|:--------|
| `@server` | Query a specific Name Server (IP or Hostname). | `dig @8.8.8.8 google.com` |
| `name` | The domain name to query. | `dig google.com` |
| `type` | DNS Record type (A, AAAA, MX, NS, TXT, ANY). | `dig google.com MX` |
| `-x <addr>` | **Reverse Lookup** (IP to Domain). | `dig -x 8.8.8.8` |
| `-p <port>` | Specify a destination port (Default: 53). | `dig @127.0.0.1 -p 5353 google.com` |
| `+short` | **Clean Output.** Show only the result, no headers. | `dig google.com +short` |
| `+trace` | Trace the path from the Root Servers to the target. | `dig google.com +trace` |
| `+noall +answer` | Display *only* the answer section (Very clean). | `dig google.com +noall +answer` |
| `axfr` | **Zone Transfer.** Request a full copy of the DNS zone. | `dig @ns1.target.com target.com axfr` |
| `+tcp` | Force query over TCP instead of UDP. | `dig +tcp google.com` |
| `-4` / `-6` | Force IPv4 or IPv6 transport. | `dig -6 google.com` |

</p>

#### Practical Examples
```bash
# 1. Standard Lookup (A Record)
dig target.com

# 2. Find Mail Servers (MX Records)
# Critical to find the email provider (e.g., Protection.outlook.com).
dig target.com MX +short

# 3. Zone Transfer (The "Holy Grail")
# Attempts to download ALL records for the domain. 
# MUST be done against the target's specific Name Server, not Google's.
dig @ns1.target.com target.com axfr

# 4. Reverse Lookup
# Find what domain lives on a specific IP.
dig -x 192.168.1.10

# 5. Debugging Propagation
# Check how a specific server sees the domain (bypassing local cache).
dig @1.1.1.1 target.com

```

<br>

## Dnsenum (DNS mapping)

Dnsenum is a multithreaded Perl script to enumerate DNS information of a domain and discover non-contiguous IP blocks. It automates the process of finding name servers, performing zone transfers, running Google scraping, and brute-forcing subdomains from a file.

```bash
# ========================================= #
#             LINUX INSTALLATION            #
# ========================================= #

# Standard on Kali Linux
sudo apt update
sudo apt install dnsenum


# ========================================= #
#                   SINTAX                  #
# ========================================= #

dnsenum [Options] <domain>
```

#### Dnsenum Cheat Sheet

<p align="center">

| Option | Description | Example |
|:-------|:------------|:--------|
| `<domain>` | The target domain. | `dnsenum target.com` |
| `--enum` | **Shortcut.** Equivalent to `--threads 5 -s 15 -w`. | `dnsenum --enum target.com` |
| `-f <file>` | **Wordlist.** Read subdomains from a file for brute force. | `dnsenum -f /usr/share/wordlists/dns.txt target.com` |
| `--threads <n>` | Set the number of threads for brute forcing. | `dnsenum --threads 10 target.com` |
| `--noreverse` | **Skip Reverse Lookup.** (Saves significant time). | `dnsenum --noreverse target.com` |
| `-o <file>` | Output results to an XML file. | `dnsenum -o output.xml target.com` |
| `--dnsserver <IP>` | Use a specific DNS server for queries (Avoids local caching). | `dnsenum --dnsserver 8.8.8.8 target.com` |
| `-r` | Enable recursive lookup on subdomains. | `dnsenum -r target.com` |
| `-w` | Enable Whois queries on discovered IP ranges. | `dnsenum -w target.com` |
| `--private` | Show and save private IPs at the end of the file. | `dnsenum --private target.com` |

</p>

#### Dnsenum Practical Examples

```bash
# 1. Quick Standard Scan
# Checks default records and attempts a Zone Transfer.
dnsenum target.com

# 2. Intense Brute Force
# Uses a custom wordlist and 20 threads to find hidden subdomains.
dnsenum -f /usr/share/wordlists/seclists/Discovery/DNS/subdomains-top1million-5000.txt --threads 20 target.com

# 3. Fast Scan (Skip Reverse Lookup)
# Reverse lookups take a long time on large ranges. Use this for speed.
dnsenum --noreverse -f common.txt target.com

# 4. Save to Report
# Generates an XML file for documentation.
dnsenum --enum -o report.xml target.com
```


<br>

## Shodan
> *HomePage: https://www.shodan.io/*
<p align="center">
    <img src="../images/shodan_logo.jpg" alt="Shodan Logo" width="200">
</p>

**Shodan is a search engine that gathers information about all devices directly connected to the Internet** (webcams, servers, IoT devices, industrial systems). If a device is directly hooked up to the Internet then Shodan queries it for various publicly-available information. The types of devices that are indexed can vary tremendously: ranging from small desktops up to nuclear power plants and everything in between. Shodan primarily collects data from **banners** â€” metadata about software running on a device. Banners contain information such as server software, supported options, welcome messages, or other details a client needs before interacting with the server.

> **Tip:** Use the [Advanced Search](https://www.shodan.io/search/advanced) page for a guided interface to build complex queries.

<br>

#### Shodan Filters Cheat Sheet

<p align="center">

| Filter | Description | Example |
|:-------|:------------|:--------|
| `ip` | Search by IP address | `ip:8.8.8.8` |
| `hostname` | Search by hostname | `hostname:google.com` |
| `port` | Filter by port number | `port:22` |
| `org` | Organization name | `org:"Google"` |
| `isp` | Internet Service Provider | `isp:"Comcast"` |
| `net` | CIDR notation network | `net:192.168.0.0/24` |
| `asn` | Autonomous System Number | `asn:AS15169` |
| `os` | Operating system | `os:"Windows 10"` |
| `product` | Software/product name | `product:nginx` |
| `version` | Software version | `version:1.19.0` |

</p>

##### Location Filters

<p align="center">

| Filter | Description | Example |
|:-------|:------------|:--------|
| `country` | 2-letter country code | `country:US` |
| `city` | City name | `city:"San Francisco"` |
| `region` | Region/state | `region:"California"` |
| `postal` | Postal code | `postal:94102` |
| `geo` | Coordinates (lat,lon,radius) | `geo:37.7,-122.4,50` |

</p>

##### HTTP Filters

<p align="center">

| Filter | Description | Example |
|:-------|:------------|:--------|
| `http.title` | Page title | `http.title:"Dashboard"` |
| `http.html` | HTML content | `http.html:"admin"` |
| `http.status` | HTTP status code | `http.status:200` |
| `http.component` | Web technology | `http.component:"WordPress"` |
| `http.favicon.hash` | Favicon hash | `http.favicon.hash:123456789` |
| `http.waf` | Web Application Firewall | `http.waf:"Cloudflare"` |

</p>

##### SSL/TLS Filters

<p align="center">

| Filter | Description | Example |
|:-------|:------------|:--------|
| `ssl` | SSL certificate content | `ssl:"target.com"` |
| `ssl.cert.issuer.cn` | Certificate issuer | `ssl.cert.issuer.cn:"Let's Encrypt"` |
| `ssl.cert.subject.cn` | Certificate subject | `ssl.cert.subject.cn:"*.target.com"` |
| `ssl.cert.expired` | Expired certificates | `ssl.cert.expired:true` |
| `ssl.jarm` | JARM fingerprint | `ssl.jarm:abc123...` |
| `has_ssl` | Has SSL enabled | `has_ssl:true` |

</p>

##### Special Filters

<p align="center">

| Filter | Description | Example |
|:-------|:------------|:--------|
| `has_screenshot` | Has screenshot | `has_screenshot:true` |
| `has_vuln` | Has known vulnerabilities | `has_vuln:true` |
| `vuln` | Specific CVE (paid) | `vuln:CVE-2021-44228` |
| `tag` | Device tag (paid) | `tag:ics` |
| `before` | Indexed before date | `before:01/01/2024` |
| `after` | Indexed after date | `after:01/01/2023` |

</p>

#### Practical Examples

```bash
# == Find Apache servers in Portugal == #
product:apache country:PT

# == Finds web servers with directory listing enabled == #
http.title:"Index of /" org:"<Target_Company>"

# == Find webcams in Portugal with screenshots == #
has_screenshot:true port:554 country:PT

# == Find the string "password" in HTTP banners == #
"password" port:80

# == Find exposed MongoDB databases == #
product:MongoDB port:27017 -authentication

# == Find devices with expired SSL certificates == #
ssl.cert.expired:true org:"<Target_Company>"

# == Find login pages == #
http.title:"login" org:"<Target_Company>"

# == Find specific web technology == #
http.component:"WordPress" country:PT
```

> **Limitations:** 
> - Some filters like `vuln` and `tag` require a paid Shodan membership.
> - Membership needed to access more than 2 pages of results.

<br>
<br>

# 3- Target Analysis

"The Software." Identifying the software stack running on the domains without touching them.

## FOCA
> *HomePage: https://github.com/ElevenPaths/FOCA*

<p align="center">
    <img width="300" src="../images/FOCA_logo.jpg" alt="FOCA Logo">
</p>

FOCA (Fingerprinting Organizations with Collected Archives) is a tool used mainly to find metadata and hidden information in the documents it scans. These documents may be on web pages, and can be downloaded and analyzed with FOCA. It is capable of analyzing a wide variety of documents, with the most common being Microsoft Office, Open Office, or PDF files, although it also analyses Adobe InDesign or SVG files, for instance.

These documents are searched for using three possible search engines: Google, Bing, and DuckDuckGo. The sum of the results from the three engines amounts to a lot of documents. It is also possible to add local files to extract the EXIF information from graphic files, and a complete analysis of the information discovered through the URL is conducted even before downloading the file.

> **Note**: This tool is only supported by Microsoft Windows.

#### Requisites:
- Microsoft Windows (64 bits). Versions 7, 8, 8.1 and 10.
- Microsoft .NET Framework 4.7.1.
- Microsoft Visual C++ 2010 x64 or greater.
- An instance of SQL Server 2014 or greater.

<br>

```powershell
### >> Windows Powershell <<
# ========================================= #
#                 REQUISITES                #
# ========================================= #

# >> INSTALL SQL SERVER EXPRESS (The Backend)
# -------------------------------------------
# Download: https://go.microsoft.com/fwlink/?linkid=866658
# Action:   Run installer -> Select "Basic" Installation type.
# Critical: Wait for "Installation has completed successfully".
# Note:     Memorize the "Instance Name" shown at the end (Default: SQLEXPRESS).

# >> INSTALL .NET FRAMEWORK 4.8 (The Runtime)
# -------------------------------------------
# Download: https://dotnet.microsoft.com/download/dotnet-framework
# Action:   Download "Runtime" version -> Install -> Reboot if asked.

# ========================================= #
#                 INSTALLATION              #
# ========================================= #

$URL = "https://github.com/ElevenPaths/FOCA/releases/latest"
# >> Download the .zip file from the Assets section.

Expand-Archive -Path "FOCA-v3.4.7.1.zip" -DestinationPath "C:\Tools\FOCA"
Start-Process "C:\Tools\FOCA\FOCA.exe" -Verb RunAs
# Note: Always run as Administrator to avoid permission errors.
```

<br>

## BuiltWith 
> *HomePage: https://builtwith.com/*

<p align="center">
    <img src="../images/Footprinting/builtWith.png" alt="BuiltWith Logo">
</p>

BuiltWith is a website profiler tool that lists all the technologies used by a specific website. BuiltWith focuses heavily on **Business Intelligence (Advertising partners, Analytics, Hosting providers) and Historical Data**. It is often used to find "Shadow IT" or forgotten sub-systems. It's for strategic, historical analysis of the domain infrastructure.


#### Use Cases for Red Team

<p align="center">

| Use Case | What to Look For |
|:---------|:-----------------|
| **Technology Stack Enumeration** | - Identify Webservers, CMS platforms, and framework versions<br> - Discover outdated software vulnerable to known exploits<br> - Map JavaScript libraries (jQuery, Bootstrap) for client-side vulnerabilities |
| **Infrastructure Mapping** | - Find hosting providers and CDN configurations<br> - Identify SSL/TLS certificate details for related domain discovery<br> - Discover name servers and DNS infrastructure |
| **Relationship Discovery** | - Track shared Analytics IDs (Google Analytics, Facebook Pixel) across multiple domains<br> - Find parent companies and subsidiary websites<br> - Identify all properties using the same infrastructure |
| **Attack Surface Expansion** | - Locate third-party integrations and plugins<br> - Discover email services for phishing vector analysis<br> - Find communication tools (Slack, Teams) for social engineering prep |
| **Historical Analysis** | - View technology changes over time to identify migration windows<br> - Detect recently added technologies that may not be fully hardened<br> - Find abandoned or forgotten systems still using legacy tech |

</p>

#### Practical Usage

```bash
# ========================================= #
#       Technology Stack Enumeration        #
# ========================================= #

# == Web interface - Technology Profile == #
https://builtwith.com/target.com

# == Information to extract == #
# - Web server (Apache, Nginx, IIS)
# - CMS platform (WordPress, Drupal, Joomla) + version
# - Programming frameworks (React, Angular, Django)
# - JavaScript libraries and versions

# ========================================= #
#          Infrastructure Mapping           #
# ========================================= #

# == Web interface - Hosting section == #
https://builtwith.com/target.com

# == Information to extract == #
# - Hosting provider (AWS, Azure, Cloudflare)
# - CDN configuration
# - SSL certificate provider
# - DNS and nameserver details
# - Email hosting service

# ========================================= #
#         Relationship Discovery            #
# ========================================= #

# == Web interface - Analytics section == #
https://builtwith.com/target.com

# == Information to extract == #
# - Google Analytics ID (UA-XXXXXX / G-XXXXXX)
# - Facebook Pixel ID
# - Other tracking codes shared across domains
# - Parent/subsidiary domain relationships

# == Reverse lookup by Analytics ID == #
https://builtwith.com/relationships/tag/UA-XXXXXX

# ========================================= #
#         Attack Surface Expansion          #
# ========================================= #

# == Web interface - Widgets & Integrations == #
https://builtwith.com/target.com

# == Information to extract == #
# - Third-party plugins and integrations
# - Payment processors
# - Chat/support widgets
# - Marketing automation tools
# - Social media integrations

# ========================================= #
#           Historical Analysis             #
# ========================================= #

# == Web interface - Technology History == #
https://builtwith.com/target.com

# == Information to extract == #
# - Technology change timeline
# - Recently added technologies (potentially not hardened)
# - Removed technologies (may still be partially accessible)
# - Migration patterns and windows
```


<br>
<br>



## Wayback Machine
> *HomePage: https://web.archive.org/*

<p align="center">
    <img src="../images/Footprinting/WayBack_Machine.png" alt="Wayback Machine Website">
</p>

The Wayback Machine is a digital archive of the World Wide Web maintained by the Internet Archive. It allows users to view archived versions of web pages across time, it's essentially a "time machine" for websites. For Red Team reconnaissance, it is invaluable for **discovering removed content, old configurations, exposed credentials, and historical attack surface**.


#### Use Cases for Red Team

<p align="center">

| Use Case | What to Look For |
|:---------|:-----------------|
| **Discover Removed Sensitive Content** | - Find old pages that exposed internal information<br>  - Locate deleted employee directories, org charts<br> - Recover removed documentation with technical details|
| **Historical Vulnerability Research** | - Identify old technology stacks that may still be partially in use<br> - Find deprecated login portals or admin panels<br> - Discover previous website versions with known vulnerabilities|
| **Credential & Configuration Leaks** | - Search for accidentally published config files<br> - Find old `.htaccess`, `robots.txt` with hidden paths<br> - Locate backup files or database dumps that were briefly exposed|
| **Social Engineering Preparation** | - Find old "About Us" pages with employee names/roles<br> - Discover previous company branding for phishing templates<br> - Identify former partnerships or vendors|
| **Attack Surface Expansion** | - Discover old subdomains or microsites<br> - Find deprecated APIs or endpoints<br> - Identify legacy systems that may still be accessible|

</p>

#### Practical Usage

```bash
# ========================================= #
#    Discover Removed Sensitive Content     #
# ========================================= #

# == Search for deleted pages and directories == #
https://web.archive.org/web/*/target.com/employees/*
https://web.archive.org/web/*/target.com/internal/*
https://web.archive.org/web/*/target.com/docs/*

# == Find old documentation and internal pages == #
waybackurls target.com | grep -iE "(internal|private|staff|employee|org-chart)"

# ========================================= #
#     Historical Vulnerability Research     #
# ========================================= #

# == View specific date snapshots to identify old tech stacks ==
https://web.archive.org/web/20180101/https://target.com
https://web.archive.org/web/20200115/https://target.com

# == Find deprecated login/admin portals ==
waybackurls target.com | grep -iE "(admin|login|portal|dashboard|cms|wp-admin)"

# == Search for old plugin/framework versions ==
waybackurls target.com | grep -iE "(wp-content|joomla|drupal|plugins)"

# ========================================= #
#      Credential & Configuration Leaks     #
# ========================================= #

# == Search for exposed configuration files == #
https://web.archive.org/web/*/target.com/robots.txt
https://web.archive.org/web/*/target.com/.htaccess
https://web.archive.org/web/*/target.com/web.config

# == Find backup files and database dumps == #
waybackurls target.com | grep -E "\.(conf|config|bak|backup|sql|db|env|yml|yaml|json)$"

# == Search for accidentally exposed sensitive files ==
waybackurls target.com | grep -E "\.(zip|tar|gz|rar|7z)$"


# ========================================= #
#       Social Engineering Preparation      #
# ========================================= #

# == Find old About Us, Team, and Contact pages == #
https://web.archive.org/web/*/target.com/about*
https://web.archive.org/web/*/target.com/team*
https://web.archive.org/web/*/target.com/contact*

# == Extract employee names and roles from archived pages == #
waybackurls target.com | grep -iE "(about|team|staff|leadership|contact|careers)"

# == Find old branding and marketing materials == #
waybackurls target.com | grep -E "\.(pdf|ppt|pptx)$" | grep -iE "(brand|marketing|press)"


# ========================================= #
#         Attack Surface Expansion          #
# ========================================= #

# == Discover old subdomains and microsites == #
https://web.archive.org/web/*/*.target.com

# == Find deprecated APIs and endpoints == #
waybackurls target.com | grep -iE "(api|v1|v2|rest|graphql|endpoint)"

# CLI tool: waybackurls (by tomnomnom)
# Install: go install github.com/tomnomnom/waybackurls@latest
waybackurls target.com | tee wayback_urls.txt

# Comprehensive file type search for attack surface
waybackurls target.com | grep -E "\.(pdf|doc|docx|xls|xlsx|xml|json|txt)$"
```

<br>

## Netcraft
> *Page: https://sitereport.netcraft.com/*

<p align="center">
    <img src="../images/Footprinting/Netcraft.png" alt="Netcraft Website">
</p>

Netcraft is a web security services company that provides a free **Site Report** tool for passive reconnaissance. It aggregates information about websites including hosting history, technology stack, SSL certificates, and risk ratings, all without directly interacting with the target.

#### Information Gathered

<p align="center">


| Category | Details |
|:---------|:--------|
| **Network** | IP address, hosting provider, ASN, nameservers |
| **Hosting History** | Historical hosting changes with dates |
| **SSL/TLS** | Certificate details, issuer, expiration, chain |
| **Technology** | Server software, frameworks, CMS detected |
| **Risk Rating** | Phishing/malware risk assessment |
| **Site Rank** | Popularity and traffic estimates |

</p>

#### Use Cases for Red Team

<p align="center">

| Use Case | What to Look For |
|:---------|:-----------------|
| **Hosting Provider Identification** | - Determine if target uses cloud (AWS, Azure, GCP) or dedicated hosting<br> - Identify shared hosting environments for potential pivot points |
| **Historical Infrastructure Changes** | - Track when the target migrated between providers<br> - Identify patterns in infrastructure changes |
| **SSL Certificate Intelligence** | - Find related domains via certificate Subject Alternative Names (SANs)<br> - Identify certificate expiration for potential attack windows |
| **Risk Assessment** | - Check if domain has been flagged for phishing/malware<br> - Assess target's overall security posture |

</p>

#### Practical Usage

```bash
# ========================================= #
#      Hosting Provider Identification      #
# ========================================= #

# == Web interface - Network section == #
https://sitereport.netcraft.com/?url=target.com

# == Information to extract == #
# - Hosting company name (AWS, Azure, GCP, DigitalOcean, etc.)
# - IP address and ASN
# - Nameservers configuration
# - Shared hosting indicators (multiple sites on same IP)

# ========================================= #
#    Historical Infrastructure Changes      #
# ========================================= #

# == Web interface - Hosting History section == #
https://sitereport.netcraft.com/?url=target.com

# == Information to extract == #
# - Timeline of hosting provider changes
# - Dates of infrastructure migrations
# - Previous IP addresses and hosts
# - Patterns indicating security updates or incidents

# ========================================= #
#        SSL Certificate Intelligence       #
# ========================================= #

# == Web interface - SSL/TLS section == #
https://sitereport.netcraft.com/?url=target.com

# == Information to extract == #
# - Certificate issuer and validity period
# - Subject Alternative Names (SANs) - reveals related domains!
# - Certificate chain and trust hierarchy
# - Expiration dates for potential attack windows
# - Protocol versions and cipher suites

# ========================================= #
#             Risk Assessment               #
# ========================================= #

# == Web interface - Risk Rating section == #
https://sitereport.netcraft.com/?url=target.com

# == Information to extract == #
# - Phishing/malware risk score
# - Historical security incidents
# - Site reputation indicators
# - Overall security posture assessment
# - Blocklist status
```

<br>
<br>

---

<br>

<div align="center">

| Previous Page | Next Page |
|:-------------------------------------------:|:---------------------------------------------:|
| [Footprinting](2.0-Footprinting.md) | [Fingerprinting](../3-Fingerprinting/3.0-Fingerprinting.md) |

</div>